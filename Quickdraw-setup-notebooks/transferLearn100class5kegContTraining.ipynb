{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.layers import *\n",
    "import keras\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Optimizer weight shape (1152, 2048) not compatible with provided weight shape (2048, 2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-62abb08e70bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./transferredLearnModel.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\HuaSheng\\AppData\\Local\\conda\\conda\\envs\\tfkeras\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    289\u001b[0m             optimizer_weight_values = [optimizer_weights_group[n] for n in\n\u001b[0;32m    290\u001b[0m                                        optimizer_weight_names]\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_weight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HuaSheng\\AppData\\Local\\conda\\conda\\envs\\tfkeras\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    101\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                                  \u001b[1;34m' not compatible with '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                                  'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Optimizer weight shape (1152, 2048) not compatible with provided weight shape (2048, 2048)"
     ]
    }
   ],
   "source": [
    "newModel = load_model('./transferredLearnModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "getInter = model.get_layer('flatten_1').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Dense(2048,activation='relu',name='fcnew')(getInter)\n",
    "x=Dropout(0.2,name='drnew')(x)\n",
    "x = Dense(2048,activation='relu',name='fcnew1')(x)\n",
    "x=Dropout(0.5,name='drnew1')(x)\n",
    "x = Dense(200,activation='softmax',name = 'output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "newModel = Model(model.input,x)\n",
    "newModel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples_per_class = 5000\n",
    "\n",
    "\n",
    "classes = ['aircraft carrier','airplane','alarm clock','ambulance','angel','ant',\n",
    "'anvil','apple','axe','banana','bandage','barn','baseball bat',\n",
    "'baseball','basket','basketball','bathtub','beach','bear','beard',\n",
    "'bed','bee','belt','bicycle','binoculars','birthday cake',\n",
    "'blueberry','book','boomerang','bottlecap','bowtie','bracelet',\n",
    "'brain','bread','broom','bulldozer','bus','bush','butterfly',\n",
    "'cactus','cake','calculator','calendar','camel','camera','campfire',\n",
    "'candle','cannon','canoe','car','carrot','cat','cello','chandelier',\n",
    "'clock','cloud','coffee cup','compass','computer','cookie','couch',\n",
    "'cow','crab','crayon','crocodile','crown','cup','diamond','dog',\n",
    "'dolphin','donut','dragon','dresser','drill','drums','duck','dumbbell','ear','elbow','elephant','envelope','eraser',\n",
    "'eye','eyeglasses','face','fan','feather','fence','finger','fire hydrant',\n",
    "'fireplace','firetruck','fish','flamingo','flashlight','flip flops',\n",
    "'floor lamp','flower','flying saucer','foot','fork','frog','frying pan',\n",
    "'garden hose','garden','giraffe','goatee','golf club','grapes','grass',\n",
    "'guitar','hamburger','hammer','hand','harp','hat','headphones',\n",
    "'hedgehog','helicopter','helmet','hexagon','hockey puck',\n",
    "'hockey stick','horse','hospital','hot air balloon','hot dog',\n",
    "'hot tub','hourglass','house plant','house','hurricane',\n",
    "'ice cream','jacket','jail','kangaroo','key','keyboard','knee',\n",
    "'knife','ladder','lantern','laptop','leaf','leg','light bulb',\n",
    "'lighter','lighthouse','lightning','line','lion','lipstick','lobster',\n",
    "'lollipop','mailbox','map','marker','matches','megaphone',\n",
    "'mermaid','microphone','microwave','monkey',\n",
    "'moon','mosquito','motorbike','mountain','mouse','moustache',\n",
    "'mouth','mug','mushroom','nail','necklace','nose','ocean',\n",
    "'octagon','octopus','onion','oven','owl',\n",
    "'paint can','paintbrush','palm tree','panda','pants',\n",
    "'paper clip','parachute','parrot','passport','peanut',\n",
    "'pear','peas','pencil','penguin','piano','pickup truck',\n",
    "'picture frame','pig','pillow']\n",
    "x_data = np.load(\"./x_data_200_classes_5k.npy\")\n",
    "\n",
    "labels = [np.full((num_examples_per_class,), classes.index(qdraw)) for qdraw in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Concat the arrays together\n",
    "y_data = np.concatenate(labels,axis=0)\n",
    "y_data.shape\n",
    "\n",
    "\n",
    "y_data = keras.utils.to_categorical(y_data,200)\n",
    "\n",
    "dataOrder =  np.random.permutation(x_data.shape[0])\n",
    "trainIdx = dataOrder[0:np.floor(0.8*dataOrder.shape[0]).astype('int32')]\n",
    "testIdx = dataOrder[(np.floor(0.8*dataOrder.shape[0]).astype('int32')+1):-1]\n",
    "\n",
    "def myGeneratorBasic(x_data,y_data,batchSize,dataOrder):\n",
    "    while True:\n",
    "        np.random.shuffle(dataOrder)\n",
    "        for i in range(0, len(dataOrder), batchSize):\n",
    "            xTrain = x_data[dataOrder[i:i+batchSize]]\n",
    "            yTrain = y_data[dataOrder[i:i+batchSize]]\n",
    "            yield({'input_1':np.array(xTrain)},{'output':np.array(yTrain)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = newModel.fit_generator(myGeneratorBasic(x_data,y_data,32,trainIdx),400,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
