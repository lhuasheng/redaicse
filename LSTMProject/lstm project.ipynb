{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8a810e8b-adbd-ec04-1102-6389c5c5e305",
    "_uuid": "8e559d056a743db182de2a261d5a907fd1781695"
   },
   "source": [
    "# RNN Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6c83e387-0dcd-c376-d297-3b346e091b90",
    "_uuid": "fe08649b621d79cd0b3b8b2dc64e46af35566996"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "3ed647af-7bd2-6381-bd08-8d7fbce13175",
    "_uuid": "8050e886743790e296ff978c9f6e5bf16eb33fdc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from string import punctuation\n",
    "from keras.models import load_model,Model\n",
    "from keras.layers import *\n",
    "import keras\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./input/train.csv\")#[:500]\n",
    "test = pd.read_csv(\"./input/test.csv\")[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "2571fee8-966a-7781-31fd-0b67ca74cc09",
    "_uuid": "d3f78e9b5e30640691e57ea02ec4941c8e90021c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabel=np.array(train['is_duplicate'])#[:500]\n",
    "train.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "d5076218-27e7-bdbe-d156-f19fa1b42511",
    "_uuid": "6f7f0955eb0baea0700d07280ccd5075ae2730d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       0\n",
      "question2       2\n",
      "is_duplicate    0\n",
      "dtype: int64\n",
      "test_id      0\n",
      "question1    0\n",
      "question2    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for any null values\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "e3dcc0bd-4810-f3c5-173f-e57d5c08ba75",
    "_uuid": "3b317cd94ca43245f4c05d1d3932c0df482ca284",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the string 'empty' to empty strings\n",
    "train = train.fillna('empty')\n",
    "test = test.fillna('empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "afee6957-0045-f900-14ad-e357799327ee",
    "_uuid": "8a71318e0ff6017ae9efaad9f0e7891d15e8374c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "What is the step by step guide to invest in share market?\n",
      "\n",
      "What is the story of Kohinoor (Koh-i-Noor) Diamond?\n",
      "What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\n",
      "\n",
      "How can I increase the speed of my internet connection while using a VPN?\n",
      "How can Internet speed be increased by hacking through DNS?\n",
      "\n",
      "Why am I mentally very lonely? How can I solve it?\n",
      "Find the remainder when [math]23^{24}[/math] is divided by 24,23?\n",
      "\n",
      "Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?\n",
      "Which fish would survive in salt water?\n",
      "\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "\n",
      "Should I buy tiago?\n",
      "What keeps childern active and far from phone and video games?\n",
      "\n",
      "How can I be a good geologist?\n",
      "What should I do to be a great geologist?\n",
      "\n",
      "When do you use シ instead of し?\n",
      "When do you use \"&\" instead of \"and\"?\n",
      "\n",
      "Motorola (company): Can I hack my Charter Motorolla DCX3400?\n",
      "How do I hack Motorola DCX3400 for free internet?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview some of the pairs of questions\n",
    "a = 0 \n",
    "for i in range(a,a+10):\n",
    "    print(train.question1[i])\n",
    "    print(train.question2[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b848afd6-2704-160e-0707-a3018f0921cf",
    "_uuid": "2acc1079bbc8e443aaa260183cc7b64399916c68",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = ['the','a','an','and','but','if','or','because','as','what','which','this','that','these','those','then',\n",
    "              'just','so','than','such','both','through','about','for','is','of','while','during','to','What','Which',\n",
    "              'Is','If','While','This']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "ff0de941-13ce-990d-2e1f-27db513655fa",
    "_uuid": "2197b254e63fe584f557f0f072e43f5c26215624",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_wordlist(text, remove_stop_words=False, stem_words=False):\n",
    "    # Clean the text, with the option to remove stop_words and to stem words.\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \" what is \", text)\n",
    "    text = re.sub(r\"What's\", \" what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"I'm\", \"I am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e-mail\", \"email\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" USA \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\" uk \", \" England \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text)\n",
    "    text = re.sub(r\"india\", \"India\", text)\n",
    "    text = re.sub(r\"switzerland\", \"Switzerland\", text)\n",
    "    text = re.sub(r\"china\", \"China\", text)\n",
    "    text = re.sub(r\"chinese\", \"Chinese\", text) \n",
    "    text = re.sub(r\"imrovement\", \"improvement\", text)\n",
    "    text = re.sub(r\"intially\", \"initially\", text)\n",
    "    text = re.sub(r\"quora\", \"Quora\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)  \n",
    "    text = re.sub(r\"demonitization\", \"demonetization\", text) \n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\"KMs\", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvotes \", \" up votes \", text)\n",
    "    text = re.sub(r\" iPhone \", \" phone \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text) \n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"gps\", \"GPS\", text)\n",
    "    text = re.sub(r\"gst\", \"GST\", text)\n",
    "    text = re.sub(r\"programing\", \"programming\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"dna\", \"DNA\", text)\n",
    "    text = re.sub(r\"III\", \"3\", text) \n",
    "    text = re.sub(r\"the US\", \"America\", text)\n",
    "    text = re.sub(r\"Astrology\", \"astrology\", text)\n",
    "    text = re.sub(r\"Method\", \"method\", text)\n",
    "    text = re.sub(r\"Find\", \"find\", text) \n",
    "    text = re.sub(r\"banglore\", \"Banglore\", text)\n",
    "    text = re.sub(r\" J K \", \" JK \", text)\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stop_words:\n",
    "        text = text.split()\n",
    "        text = [w for w in text if not w in stop_words]\n",
    "        text = \" \".join(text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "f4c3b53d-f02a-979f-bc09-1c5bccbbf1be",
    "_uuid": "4076117ebe836e6c405ea1fb965121dbd907c72a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_questions(question_list, questions, question_list_name, dataframe):\n",
    "    '''transform questions and display progress'''\n",
    "    for question in questions:\n",
    "        question_list.append(text_to_wordlist(question).lower())\n",
    "        if len(question_list) % 100000 == 0:\n",
    "            progress = len(question_list)/len(dataframe) * 100\n",
    "            print(\"{} is {}% complete.\".format(question_list_name, round(progress, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "d58248eb-f5b6-94df-ee49-34fd442e5cba",
    "_uuid": "f897afe126f5afdfb397b6539a396aea0c9f509f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_question1 is 24.7% complete.\n",
      "train_question1 is 49.5% complete.\n",
      "train_question1 is 74.2% complete.\n",
      "train_question1 is 98.9% complete.\n"
     ]
    }
   ],
   "source": [
    "train_question1 = []\n",
    "process_questions(train_question1, train.question1, 'train_question1', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "9ec0ed1e-5add-50d5-47a1-46290d895be4",
    "_uuid": "178dffe31e7892e97a6ffe86d6b6192ee3c6a585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_question2 is 24.7% complete.\n",
      "train_question2 is 49.5% complete.\n",
      "train_question2 is 74.2% complete.\n",
      "train_question2 is 98.9% complete.\n"
     ]
    }
   ],
   "source": [
    "train_question2 = []\n",
    "process_questions(train_question2, train.question2, 'train_question2', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "7906e1a7-e7b3-a80c-94bb-c112966c01d1",
    "_uuid": "d3b6c54dcc96ec09ac7e93606009f90318686119",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_question1 = []\n",
    "process_questions(test_question1, test.question1, 'test_question1', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b8410fa8-b381-d9a7-e38d-e3356ef40025",
    "_uuid": "5a44c4cee70499c00a1c2311438320252c7db3ae",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_question2 = []\n",
    "process_questions(test_question2, test.question2, 'test_question2', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "e84f3837-b714-9ee8-df9c-2be091755cee",
    "_uuid": "a94d2c2f63430ac718f8b6af537af820ae38c853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the step by step guide to invest in share market in india \n",
      "what is the step by step guide to invest in share market \n",
      "\n",
      "what is the story of kohinoor koh i noor diamond \n",
      "what would happen if the indian government stole the kohinoor koh i noor diamond back \n",
      "\n",
      "how can i increase the speed of my internet connection while using a vpn \n",
      "how can internet speed be increased by hacking through dns \n",
      "\n",
      "why am i mentally very lonely how can i solve it \n",
      "find the remainder when math 23 24 math is divided by 24 23 \n",
      "\n",
      "which one dissolve in water quickly sugar salt methane and carbon di oxide \n",
      "which fish would survive in salt water \n",
      "\n",
      "astrology i am a capricorn sun cap moon and cap rising what does that say about me \n",
      "i am a triple capricorn sun moon and ascendant in capricorn what does this say about me \n",
      "\n",
      "should i buy tiago \n",
      "what keeps childern active and far from phone and video games \n",
      "\n",
      "how can i be a good geologist \n",
      "what should i do to be a great geologist \n",
      "\n",
      "when do you use instead of \n",
      "when do you use instead of and \n",
      "\n",
      "motorola company can i hack my charter motorolla dcx3400 \n",
      "how do i hack motorola dcx3400 for free internet \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview some transformed pairs of questions\n",
    "a = 0 \n",
    "for i in range(a,a+10):\n",
    "    print(train_question1[i])\n",
    "    print(train_question2[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "ed5d21f4-1b2c-0645-58e1-886f3aef0f12",
    "_uuid": "4db0e37ece288c031a081cd43dfcb62073d9c10e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HuaSheng\\AppData\\Local\\conda\\conda\\envs\\tfkeras\\lib\\site-packages\\keras\\preprocessing\\text.py:90: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 85424 unique tokens.\n",
      "Shape of data tensor: (404290, 30)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    2    3    1 1221   60 1221 2569    7  578    8  761  381    8   36]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 100 \n",
    "\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train_question1+train_question2+test_question1+test_question2)\n",
    "sequencestr1 = tokenizer.texts_to_sequences(train_question1)\n",
    "sequencestr2 = tokenizer.texts_to_sequences(train_question2)\n",
    "sequencestt1 = tokenizer.texts_to_sequences(test_question1)\n",
    "sequencestt2 = tokenizer.texts_to_sequences(test_question2)\n",
    "#print(tokenizer)\n",
    "#print(sequences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "datatr1 = pad_sequences(sequencestr1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "datatr2 = pad_sequences(sequencestr2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "datatt1 = pad_sequences(sequencestt1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "datatt2 = pad_sequences(sequencestt2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', datatr1.shape)\n",
    "print(datatr1[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('./', 'glove6B100d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85425, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainLabel = to_categorical(trainLabel,2)\n",
    "trainLabel[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "tr1Inp (InputLayer)              (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tr2Inp (InputLayer)              (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 30, 100)       8542500     tr1Inp[0][0]                     \n",
      "                                                                   tr2Inp[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 30, 100)       60400       embedding_1[0][0]                \n",
      "                                                                   embedding_1[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 30, 100)       0           bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 30, 100)       0           bidirectional_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 100)           60400       dropout_1[0][0]                  \n",
      "                                                                   dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 100)           400         bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 100)           400         bidirectional_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 100)           0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           12928       dropout_2[0][0]                  \n",
      "                                                                   dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 128)           512         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 128)           512         dense_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 128)           0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           16512       dropout_3[0][0]                  \n",
      "                                                                   dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 128)           0           dense_2[0][0]                    \n",
      "                                                                   dense_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 128)           0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 256)           33024       dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 256)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 256)           65792       dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 2)             514         dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 8,793,894\n",
      "Trainable params: 250,482\n",
      "Non-trainable params: 8,543,412\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def processBlk(sequenceInp):\n",
    "    embedded_sequences = embedding_layer(sequenceInp)\n",
    "    x = Conv1D(128, 5, activation='relu',padding='same')(embedded_sequences)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(128, 5, activation='relu',padding='same')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(128, 5, activation='relu',padding='same')(x)\n",
    "    x = MaxPooling1D(2)(x)  # global max pooling\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return(x)'''\n",
    "''' x = Bidirectional(LSTM(32,return_sequences=True))(embedded_sequences)\n",
    "    x = Bidirectional(LSTM(32,return_sequences=True))(x)'''\n",
    "\n",
    "biLSTM1 = Bidirectional(LSTM(50,return_sequences=True))\n",
    "biLSTM2 = Bidirectional(LSTM(50))\n",
    "dense1 =  Dense(128, activation='relu')\n",
    "dense2 =  Dense(128, activation='relu')\n",
    "def processBlk(sequenceInp):\n",
    "    embedded_sequences = embedding_layer(sequenceInp)\n",
    "    x = biLSTM1(embedded_sequences)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = biLSTM2(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = dense1(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = dense2(x)\n",
    "    return(x)\n",
    "\n",
    "sequence_inputtr1 = Input(shape=(MAX_SEQUENCE_LENGTH,),name = 'tr1Inp', dtype='int32')\n",
    "x1 = processBlk(sequence_inputtr1)\n",
    "sequence_inputtr2 = Input(shape=(MAX_SEQUENCE_LENGTH,),name = 'tr2Inp', dtype='int32')\n",
    "x2 = processBlk(sequence_inputtr2)\n",
    "\n",
    "subtract_layer = Lambda(lambda inputs: inputs[0] - inputs[1])\n",
    "\n",
    "x = subtract_layer([x1, x2])\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "preds = Dense(2, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model([sequence_inputtr1 ,sequence_inputtr2 ], preds)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363861 samples, validate on 40429 samples\n",
      "Epoch 1/5\n",
      "363861/363861 [==============================] - 694s - loss: 0.5656 - acc: 0.6977 - val_loss: 0.5990 - val_acc: 0.6751\n",
      "Epoch 2/5\n",
      "363861/363861 [==============================] - 707s - loss: 0.5013 - acc: 0.7488 - val_loss: 0.4856 - val_acc: 0.7541\n",
      "Epoch 3/5\n",
      "363861/363861 [==============================] - 758s - loss: 0.4714 - acc: 0.7674 - val_loss: 0.4592 - val_acc: 0.7724\n",
      "Epoch 4/5\n",
      "363861/363861 [==============================] - 730s - loss: 0.4532 - acc: 0.7801 - val_loss: 0.4449 - val_acc: 0.7838\n",
      "Epoch 5/5\n",
      "363861/363861 [==============================] - 710s - loss: 0.4401 - acc: 0.7874 - val_loss: 0.4531 - val_acc: 0.7779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bda890d978>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# happy learning!\n",
    "model.fit([datatr1,datatr2], trainLabel, validation_split=0.1,shuffle=True,\n",
    "          epochs=5, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./quora100dglove.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.5'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
