{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def addDS():\n",
    "    total = []\n",
    "    src1 =[]\n",
    "    src2 =[]\n",
    "    #x1 = np.arange(0,101)\n",
    "    #x2 = np.arange(0,101)\n",
    "    x1 = np.random.randint(0,100,size=(1000))\n",
    "    x2 = np.random.randint(0,100,size=(1000))\n",
    "    for u  in x1:\n",
    "        for v in x2:\n",
    "            singleInst = [int(d) for d in str(np.binary_repr(u+v,width=8))]\n",
    "            total += [singleInst]\n",
    "            src1 += [u]\n",
    "            src2 += [v]\n",
    "    return total,src1,src2\n",
    "\n",
    "x1 = np.random.randint(0,100,size=(10))\n",
    "print(x1)\n",
    "\n",
    "    \n",
    "\n",
    "total,x1,x2 = addDS()\n",
    "\n",
    "print(len(x1))\n",
    "\n",
    "dataIdx = np.random.permutation(len(total))\n",
    "x1 = np.array(x1)\n",
    "x2 = np.array(x2)\n",
    "total = np.array(total)\n",
    "xtrain = np.hstack((x1[dataIdx,np.newaxis],x2[dataIdx,np.newaxis]))\n",
    "ytrain = total[dataIdx,:]\n",
    "xtrain = np.divide(xtrain,100)\n",
    "\n",
    "print(xtrain[50])\n",
    "print(np.argmax(ytrain[50]))\n",
    "\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "\n",
    "inp = Input(shape=(2,))\n",
    "x = Dense(1,activation='relu')(inp)\n",
    "x = Dense(40,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(40,activation='relu')(x)\n",
    "out = Dense(8,activation = 'sigmoid')(x)\n",
    "\n",
    "model = Model(inp,out)\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['acc'])\n",
    "\n",
    "print(model.metrics_names)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,epsilon=0.01,cooldown=1,\n",
    "              patience=2, min_lr=0.0001)\n",
    "K.set_value(model.optimizer.lr, 0.001)\n",
    "model.fit(xtrain,ytrain,batch_size=32,epochs=1000,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataIdx = np.random.permutation(len(total))\n",
    "x1 = np.array(x1)\n",
    "x2 = np.array(x2)\n",
    "total = np.array(total)\n",
    "xtrain = np.hstack((x1[dataIdx,np.newaxis],x2[dataIdx,np.newaxis]))\n",
    "ytrain = total[dataIdx]\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "\n",
    "\n",
    "\n",
    "inp = Input(shape=(2,))\n",
    "x = Dense(100,activation='relu')(inp)\n",
    "x = Dense(100,activation='relu')(x)\n",
    "x = Dense(100,activation='relu')(x)\n",
    "out = Dense(1)(x)\n",
    "\n",
    "model = Model(inp,out)\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['acc'])\n",
    "model.fit(xtrain,ytrain,batch_size=2,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def addDS():\n",
    "    total = []\n",
    "    src1 =[]\n",
    "    src2 =[]\n",
    "    x1 = np.arange(0,101)\n",
    "    x2 = np.arange(0,101)\n",
    "    for u  in x1:\n",
    "        for v in x2:\n",
    "            total += [u+v]\n",
    "            src1 += [u]\n",
    "            src2 += [v]\n",
    "    return total,src1,src2\n",
    "\n",
    "total,x1,x2 = addDS()\n",
    "print(len(total))\n",
    "\n",
    "dataIdx = np.random.permutation(len(total))\n",
    "x1 = np.array(x1)\n",
    "x2 = np.array(x2)\n",
    "x1 =keras.utils.to_categorical(x1,101)\n",
    "x2 =keras.utils.to_categorical(x2,101)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.hstack((x1[dataIdx,:],x2[dataIdx,:]))\n",
    "total = np.array(total)\n",
    "ytrain = total[dataIdx]\n",
    "ytrain = keras.utils.to_categorical(ytrain,201)\n",
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(xtrain[50])\n",
    "print(np.argmax(ytrain[50]))\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "\n",
    "\n",
    "inp = Input(shape=(202,))\n",
    "x = Dense(202,activation='tanh')(inp)\n",
    "x = Dense(202,activation='tanh')(x)\n",
    "x = Dense(202,activation='tanh')(x)\n",
    "out = Dense(201,activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inp,out)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "model.fit(xtrain,ytrain,batch_size=2,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [ 0, 1,2]\n",
    "b= keras.utils.to_categorical(a,3)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
